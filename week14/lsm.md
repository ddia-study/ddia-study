# 12장 데이터 시스템의 미래

- 책의 목적 : 어플리케이션과 시스템을 신뢰할 수 있고 확장 가능하며 유지보수하기 쉽게 만드는 방법
- 미래 고찰의 목적 : 견고하고 정확하며 발전 가능한, 궁극적으로 인류에 도움이 되는 애플리케이션을 설계하는 방법을 발견하는 것

---

- 데이터 통합
    - 책의 흐름 : 어떤 문제에 대한 몇 가지 해결책을 놓고 장점과 단점 그리고 트레이드 오프 설명
    - 선택의 폭이 넓을 경우 : 소프트웨어 제품과 그 제품이 잘 어울리는 환경 사이의 대응 관계를 파악이 중요
    
    - 파생 데이터에 특화된 도구의 결합 : 나무가 아닌 숲을 보기 위해 줌 아웃해서 조직 전체 데이터 플로우를 고려해야 할 때 데이터 통합의 필요성이 명백해짐
    - 데이터 플로에 대한 추론
        - 다른 데이터 접근 양식을 만족하기 위해 같은 데이터의 사본을 여러 저장소에 유지할때 입출력을 분명히 알 필요가 있다.(처음 기록하는 장소, 어떤 표현형, ..)
        - 파생 데이터 시스템은 이벤트 로그를 기반으로 갱신하면 결정적이고 멱등성을 지녀 결함에서 복구하기 상당히 쉬워짐
        
    - 파생 데이터 대 분산 트랜잭션
        - 파생 데이터와 분산 트랜잭션은 다른 방식으로 유사한 목표 달성
            - 분산 트랜 잭션
                - 상호 배타적인 잠금을 사용해 쓰기 순서 결정(2PL), CDC 와 이벤트 소싱은 순서를 결정하는데 로그를 사용
                - 원자적 커밋을 사용해 변경 효과가 정확히 한 번 나타나도록 보장
            - 파생 데이터 시스템
                - 파생 데이터 시스템 : 비동기로 갱신되므로 동시간 갱신 보장 X
        
    - 전체 순서화의 제약
        - 작은 시스템에서의 이벤트 로그의 순서 전체 보장 가능, but  규모가 커지면 한계가 들어남
            - 모든 이벤트가 단일 리더 노드를 통하면 제약이 존재
            - 지역적으로 분산된 데이터 센터의 경우 각 이벤트끼리의 순서가 정해지지 않음
        - 전체 순서 브로드캐스트 : 이벤트의 전체 순서를 결정하는 것(합의와 동등)
    
    - 일괄 처리와 스트림 처리
        - 데이터 통합의 목표는 데이터를 올바른 장소에 올바른 형태로 두는 것
        - 입력을 소비해 형태를 바꾸고 필터링하고 집계해 모델을 학습하고 평가한 뒤 마지막에는 적절한 출력으로 기록
        - 일괄 처리 vs 스트림 처리
            - 일괄 처리는 끝이 유한한 반면 스트림 처리는 끝이 없는 데이터셋 상에서 운영
            - 스파크는 일괄 처리 엔진 상에서 스트림을 마이크로 일괄 처리 단위로 나누어 일괄 처리
    - 파생 상태 유지
        - 일괄 처리는 결정적이고 출력이 입력에만 의존하며 명시적 출력 외에 다른 부수 효과가 없는 순수 함수 장려
        - 입력과 출력을 잘 정의한 함수 → 내결함성에 도움 + 조직 내의 데이터플로 추론을 단순화함
        - 파생 데이터가 검색 색인, 통계 모델, 캐시 인지 여부와 상관 없이, 한 가지로 부터 다른 것을 파생하는 데이터 파이프라인 관점에서 생각하는 것 도움 많이 됨
        - 데이터 파이프라인: 함수형 애플리케이션 코드를 통해 한 시스템의 상태 변화를 밀어 넣고 결과를 파생 시스템에 적용
    
    - 애플리케이션 발전을 위한 데이터 처리
        - 파생 데이터를 유지할 때 일괄 처리와 스트림 처리는 모두 유용
        - 스트림 처리 → 입력의 변화를 빠르게 파생 뷰에 반영
        - 일괄 처리 시스템 : 상당한 양의 과거 데이터를 재처리해 기존 데이터셋을 반영한 새 파생 뷰 만들 수 있음
        - 파생 뷰를 사용하면 점진적으로 발전이 가능 (점차 변경하는 방식)
        
    - 람다 아키텍처
        - 입력 데이터를 불변 이벤트로서 증가하기만 하는 데이터셋에 추가하는 방식으로 기록
        - 하둡 맵리듀스 같은 일괄 처리 시스템과 스톰 같은 분리된 스트림 처리 시스템을 함께 운용
        - 데이터 시스템 설계를 향상시키는 데 영향을 준 아이디어, 불변 이벤트 스트림에 대한 뷰를 파생하고 필요할 떄 이벤트를 재처리하는 원리를 보급

---

- 데이터베이스 언번들링
    - 데이터베이스, 하둡, 운영체제 → 데이터를 저장하고 처리하며 질의도 함
    - 유닉스는 하드웨어를 얇게 감싼다는 “간단하다”, 관계형 데이터베이스는 강렬한 인프라를 활용 가능하다는 뜻으로 “간단하다”
    
    - 데이터 저장소 기술 구성하기
        - 데이터베이스가 제공하는 기능
            - 보족 색인은 필드 값을 기반으로 레코드를 효율적으로 검색할 수 있는 기능
            - 구체화 뷰는 질의 결과를 미리 연산한 캐시의 일종
            - 복제 로그는 데이터의 복사본을 다른 노드에 최신 상태로 유지하는 기능
            - 전문 검색 색인은 텍스트에서 키워드 검색을 가능하게 하는 기능
        
    - 색인 생성하기
        - CREATE INDEX 실행시
            1. 데이터베이스는 테이블의 일관된 스냅숏을 사용해 스캔하고 색인할 필드 값을 모두 골라 정렬 + 색인에 기록
            2. 일관된 스냅숏을 만든 이후에 실행된 쓰기의 백로그를 처리
            3. 트랜잭션이 테이블에 쓸 때마다 꾸준히 색인에 반영
    
    - 모든 것이 메타데이터베이스
        - 서로 다른 저장소와 처리 도구를 사용하지만 하나의 응집된 시스템을 구성하는 방법
            - 연합 데이터베이스 : 읽기를 통합
                - 많은 하단 저장소 엔진과 처리 메서드를 통합해 질의하는 인터페이스 제공
                - 연합 질의 인터페이스는 고수준 질의 언어와 시맨틱을 사용하지만 구현이 복잡한 단일 통합 시스템이라는 RDB 전통을 따름
                - 다른 여러 시스템을 읽기 전용으로 질의하는 문제를 해결하지만 여러 시스템에 걸친 쓰기를 동기화에는 적합하지 않은 해결책
                
            - 언번들링 데이터베이스 : 쓰기를 통합
                - 저장소 시스템들을 신뢰성 있게 결합하기 쉽게 만드는 것 = 데이터베이스의 색인 유지 기능을 다른 기술에 걸친 쓰기를 동기화할 수 있는 방식으로 언번들링하는 방식
                - 저수준 API를 통해 통신 + 셸 같은 고수준 언어를 사용해 구성하는 것도 가능
            
            - 언번들링이 동작하게 만들기
                - 여러 저장 시스템에 적용되는 쓰기를 동기화하는 것은 어려움
                - 전통적인 방법은 이종 저장소 시스템 간 분산 트랜잭션 사용 → 잘못
                - 멱등성을 기반으로 쓰기를 수행하는 비동기 이벤트 로그를 사용하는 편이 훨씬 더 강력하고 현실적인 접근법, 순서가 정해진 이벤트 로그
                - 로그 기반 통합의 장점 : 구성 요소 간 느슨한 결합
                

---

- 데이터플로 주변 애플리케이션 설계
    - 데이터베이스 인사이드 아웃 : 애플리케이션 코드로 특화된 저장소와 처리 시스템을 조립하는 언번들링 데이터베이스 접근법
    - 스프레드 시트 vs 현대 데이터 시스템 : 내결함성과 확장성이 있어야 하고 지속성 있게 데이터를 저장해야함
    - 파생 함수로서의 애플리케이션 코드
        - 데이터셋이 다른 데이터셋으로부터 파생될 때에는 변환 함수 몇 가지를 거침(보조 색인, 모신러닝 시스템, …)
        - 파생 데이터셋을 생성하는 함수가 보조 색인 생성 함수와 비슷비슷한 표준 함수가 아니라면 사용자 정의 코드를 써서 애플리케이션에 특화된 측면을 다뤄야함
    - 스트림 처리자와 서비스
        - 최근 유행 REST API와 같은 동기 네트워크 요청을 통해 통신하는 서비스의 집합
        - 데이터 플로 접근법은 빠르고 다른 서비스 장애에도 잘 버틸 수 있음(내결함성)
    - 파생 상태 관찰하기
        - 쓰기 경로 : 데이터 플로 시스템이 파생 데이터셋을 생성하고 최신 상태로 유지하는 과정
        - 파생 데이터셋을 생성하는 이유 : 이후에 다시 질의할 가능성이 크기 때문
        - 읽기 경로 : 데이터의 여정 중 누군가 요청했을 때만 발생한 부분
        - 쓰기 경로 → 데이터의 여정 중 미리 계산된 부분
    - 구체화 뷰와 캐싱
        - 쓰기 경로는 색인을 갱신하고 읽기 경로는 색인을 사용해 키워드를 찾음
        - 쓰기는 문서에 출현한 모든 용어의 색인 항목을 갱신해야 함
        - 읽기는 질의에 포함한 각 단어를 검색한 다음, 질의에 포함된 모든 단어를 포함하는 문서를 찾거나 어떤 것이든 포함하는 문서를 찾음(논리 Boolean 적용)
        - 색인이 없다면 검색 질의는 모든 문서를 스캔(쓰기 경로 양은 줄지만 읽기 경로 작업 늘어남)
        - 구체화 뷰 : 공통적인 질의 집합의 검색 결과를 미리 계산해 두는 방법
    
    - 오프라인 대응 가능한 상태 저장 클라이언트
        - 클라이언트는 대체로 상태 비저장
        - 전통적으로 웹 브라우저는 상태 비저장 클라이언트 - 인터넷 연결 됐을 대만 유용한 일 가능
        - SPA, 모바일등 상태 저장이 가능해짐 → 오프라인 우선 어플리케이션에 다시 한 번 관심을 일으키게 됨
    
    - 상태 변경을 클라이언트에게 푸쉬하기
        - 서버에서 데이터가 변경된다면 페이지가 새로 로드될 때가지 브라우저는 해당 변경 사항을 알 수 없음
        - 특정 시점의 데이터만 읽고 해당 데이터는 정적이라 가정 → 명시적으로 폴링하지 않으면 신선도가 떨어지는 캐시
        - 서버 전송 이벤트와 웹소켓은 TCP 접속 유지시 서버가 주도적으로 메시지 보냄 → 신선도 유지
        - 쓰기 경로와 읽기 경로 모델 측면에서 상태 변화를 적극적으로 클라이언트 장치에까지 푸시하면 최종 사용자까지 확장됨
        
    - 읽기도 이벤트다
        - 질의 요청시에 저장소가 읽기 경로와 쓰기 경로 사이의 경계로 작동
        - 스트림 처리자도 집계와 조인을 수행할 때 상태 유지가 필요함
        - 읽기 이벤트 로그를 기록하면 잠재적으로 인과적 의존성과 시스템 전체의 데이터 출처를 추적 가능
        

---

- 정확성을 목표로
    - 데이터 베이스의 경우 오류가 영원히 지속될 가능성이 있음, 신중하게 생각
    - 신뢰성 있고 ‘정확한’ 애플리케이션을 구축하기를 원함
    - 데이터베이스의 관한 종단 간 논증
        - 애플리케이션이 직렬성 트랜잭션과 같은 비교적 강력한 안정성 속성을 지원하는 데이터 시스템을 사용한다고 해서 애플리케이션에 데이터 유실과 손상이 없을 것이라는 보장은 없음
    - 연산자의 정확한 한 번 실행
        - 정확한 한 번 은 연산이 어떤 결함 때문에 실제로 연산자를 재시도했더라도 결함이 없었던 것과 동일한 결과를 최종적으로 반환
        - 연산을 멱등으로 만드는 것
    
    - 중복 억제
        - TCP 스택 → 애플리케이션 전달시 : 잃어버린 패킷 재전송 + 중복 패킷 제거
        - TCP 연결 문맥 내에서만 작동
        - commit 성공 후에 응답에서의 오류가 발생하면 재전송이 필요하게 됨 → 멱등으로 만들기
    
    - 유일성 제약 조건은 합의가 필요하다.
        - 유일성 제약 조건을 강제하기 위해서는 합의가 필요함
        - 단일 노드를 리더로 만들고 해당 노드가 모든 결정을 하게끔 책임을 부여하는 것, but 리더 장애시 다시 합의 문제로 돌아가게 됨
        - 유일성 검사 → 유일성이 필요한 값을 기준으로 파티셔닝하면 확장 가능
    
    - 적시성과 모결성
        - 트랜잭션의 편리한 속성 : 선형성이 있음
        - 다중 단계 스트림 처리자를 거처 연산을 언번들링하는 경우와 다름
        - 적시성 : 사용자가 시스템을 항상 최신 상태로 관측 가능
        - 무결성 : 손상이 없음, 누락 및 모순된 데이터가 없음
        - 적시성 위반 → 최종적 일관성, 무결성 위반 → 영구적 불일치
        
    - 데이터플로 시스템의 정확성
        - ACID 트랜잭션은 대게 적시성과 무결성 양쪽 모두를 보장
        - 정확히 한 번 or 결과적으로 한 번은 무결성을 보존하는 매커니즘
        - 신뢰성 있는 스트림 처리 시스템 → 분산 트랜잭션과 원자적 커밋 프로토콜 없이 무결성을 보존 가능
            - 쓰기 내용을 단일 메시지로
            - 결정적 파생 함수를 사용해 단일 메시지에서 모든 상태 갱신을 파생하기
            - 클라이언트가 생성한 요청 ID를 모든 처리 단계를 통해 전달하기
        
    - 느슨하게 해석되는 제약 조건
        - 유일성 제약 조건을 강제하려면 합의가 필요하다.
        - 모든 이벤트를 단일 노드를 통해 특정 파티션으로 보내 처리하는 방식으로 구현
        - 실제로는 완화된 유일성 개념 사용
            - 같은 좌석을 동시에 예약한 다면 한 사람에게 사과 메시지를 보내 다른 좌석을 고르게 끔 설정 → 보상 트랜잭션
            - 재고 이상의 주문이 들어가면 배송 지연에 대해 사과하고 가격을 할인
            - 항공사에서 초과 예약을 받는 경우 → 실제 초과 수요가 발생하는 경우 보상 처리
            - 은행에서 초과 인출 금액에 대한 수수료를 부과함
    
- 믿어라. 하지만 확인해라.
    - 어떤 것은 잘못될 테지만 다른 것은 그렇지 않을 것 → 시스템 모델
    - 널리 사용되는 소프트웨어 소스도 버그가 있음
    - 약속을 맹목적으로 믿지 마라. → 버그를 고치고 오류의 원인을 추적하기 위해 데이터가 손상됐는지 찾는 방법 마련 필요. - > 감사(무결성 체크 방법)
    - 감사 데이터 시스템용 도구
        - 애플리케이션 스스로 감사 메커니즘을 구현하는 경우 → 감사 테이블에 모든 변경 사항 로그로 남김
        - 암호화 도구를 사용해 시스템의 무결성을 증명(비트코인, …)
        - 본질적으로 데이터 모델과 트랜잭션 메커니즘을 사용하는 분산 데이터베이스로 신뢰하기 어려운 조직에서 다른 복제본 호스팅 가능
        - 지속적으로 다른 복제본 무결성 확인 & 실행해야 할 트랜잭션에 동의하는 합의 프로토콜 사용
        - 위 기술이 소모적 → 트랜잭션 처리량은 낮은데 기술보다 정치적인 이유
        
- 옳은 일하기
    - 소프트웨어 엔지니어도 윤리적 책임을 져야 함
    - 예측 분석 - 예측으로 인해 개인의 삶에 직접적인 영향을 줌, 조금이라도 의심스러우면 아니오, 자동화 시스템에선 무죄 추정이 아니라 유죄 증명 없이 유죄로 사회 배제 시킬 수 있음
    - 편견과 차별 - 알고리즘에 투입된 입력에 시스템적 편견이 있다면 시스템은 편견을 학습하고 편견을 증폭해서 출력을 내보낼 가능성이 높음
    - 책임과 의무 - 신용등급 기관(데이터로 사람에 관한 결정을 내림), 머신러닝의 경우 결정의 이유가 이해하기 어려움
    - 피드백 루프 - 고정관념과 오보, 양극화를 불러오는 에코 채임버가 될 수 있음
    - 사생활과 추적 - 사용자 추적은 개인을 위한 것이 아니라 서비스에 돈을 대는 광고주의 필요로 제공, 데이터 수집 그 자체에도 윤리적인 문제가 있음
    - 동의와 선택의 자유 - 좋은 서비스를 위해 필수적이라는 사용자 동의 → 개인 정보 보호 정책은 보기보다 훨씬 애매함, 약관은 사용자가 아닌 서비스가 설정
    - 사생활과 데이터 사용 - SNS에 삶에 관한 모든 것을 게시, 기업은 데이터 수집이 얼마나 침입적인지에 대한 질문 회피 → 사용자 인식을 관리하는데 집중.
    - 산업 혁명의 기억 - 데이터는 정보화 시대의 본질적인 특징, 산업혁명 때와 같이 데이터 수집과 사용 역시 직면하는 중요한 이슈
    - 법류과 자기 규제 - 데이터 보호법으로 개인의 권리를 보호할 수 있음 → 효과적?, 기업과 소프트웨어 개발자는 사용자 데이터가 어떻게 사용되는지 감추지 않고 최종 사용자에게 교육할 책임이 있음