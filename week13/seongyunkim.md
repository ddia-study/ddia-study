# 11. 스트림 처리

일괄 처리: 입력 파일 집합을 읽어 새로운 파일 집합 (파생 데이터)를 출력 → 입력을 사전에 알려진 유한한 크기로 한정 (입력이 끝나는 시점을 알 수 있음)

실제로는 데이터가 시간이 지나면서 점진적으로 도착 (데이터가 절대 완료되지 않음)

따라서, 일괄 처리는 인위적으로 데이터 청크를 나눠야 함 (ex. 하루 단위) → 단위가 지나야 반영된다는 문제점

스트림: 시간 흐름에 따라 점진적으로 생산된 데이터. 고정된 시간 조각 개념을 버리고 이벤트가 발생할 때마다 점진적으로 처리

## 이벤트  스트림 전송

레코드(이벤트): 특정 시점에 일어난 사건에 대한 독립된 불변 객체 (타임스탬프 포함)

이벤트 부호화를 통해 DB에 저장하거나 네트워크를 통해 전송할 수 있음

Producer가 이벤트를 만들면 Consumer가 처리. Topic으로 관련 이벤트를 묶음

Producer와 Consumer를 DB를 통해 연결(폴링 방식)한다면, 폴링 오버헤드가 커 새로운 이벤트 발생 시 Consumer에게 알리는 편(ex. 트리거)이 낫다.

### 메세징 시스템

이벤트를 Consumer에게 전달하는 목적으로 개발

유닉스 파이프, TCP는 전송자 하나를 정확히 수신자 하나에 연결

이를 확장해 메세징 시스템은 같은 Topic에 대해 다수의 Producer가 메세지를 전송하고 다수의 Consumer가 메세지를 받을 수 있음

- Publish/Subscribe 모델
    - Consumer의 메세지 처리 속도보다 Producer가 빠르게 메세지를 전송하는 경우 어떻게 처리할 것인가?
        - 버리기
        - 큐에 버퍼링
        - Back Pressure (Producer가 더 보내지 못하게 막음)
    - Node가 일시적으로 죽으면 손실되는 메세지가 있을까?
        - 지속성을 위해서는 디스크에 기록하거나 복제본 생성 필요 (비용 발생)
        - 메세지를 잃어도 괜찮다면  하드웨어 처리량을 늘리고 지연시간을 낮출 수 있음
- Producer가 Consumer로 직접 메세지 전달하기
    - 메세지 유실 가능성을 고려해 애플리케이션 코드를 작성해야
    - Producer와 Consumer 모두 항상 온라인 상태라고 가정
    - UDP 멀티캐스트, Web hook (이벤트 발생할 때 마다 콜백 URL로 요청을 보냄)
- 메세지 브로커 (메세지 큐)
    - Producer는 브로커로 메세지를 전송하고 Consumer는 브로커에서 메세지를 읽음
    - Consumer가 오프라인 상태여도 대처 가능
    - Producer는 브로커가 메세지를 버퍼에 넣었는지만 확인하고 Consumer가 메세지 처리하기 까지 기다리지 않음 (비동기)
- 메세지 브로커 vs 데이터 베이스
    - 데이터 베이스는 삭제될 때 까지 데이터를 보관. 메세지 브로커 (대부분은) Consumer가 처리하고 메세지를 삭제
    - 메세지 브로커는 메시지를 빨리 지우기 때문에 큐 크기가 작다고 가정. Consumer가 느려 버퍼링한 메세지가 많다면 처리 시간, 처리량이 저하 (메모리에 저장하고 메세지가 많아지면 디스크로)
    - 클라이언트에서 필요한 데이터를 선택하기 위해 데이터 베이스는 색인. 메세지 브로커는 패턴과 부합하는 토픽의 부분집합을 구독
    - 데이터 베이스는 데이터가 변해도 다시 질의(폴링)하지 않으면 변경 사실을 모름. 메세지 브로커는 데이터가 변하면 (새 메세지가 생기면) 클라이언트에게 알려줌
    
    → 이러한 메세지 브로커 특징은 AMQP와 같은 표준으로 캡슐화되어 구현 (RabbitMQ 등)
    
- 복수 소비자
    - 로드 밸런싱
        - 각 메세지는 브로커가 지정한 Consumer 중 하나로 전달
        - Consumer는 해당 토픽의 메세지를 처리하는 작업을 공유
        - 메세지 처리 비용이 비싸 처리를 병렬화하기 위해 소비자를 추가할 때 유용
    - 팬아웃
        - 각 메세지는 모든 Consumer에게 전달
        - 각 Consumer가 독립적으로 동일한 메세지를 청취
- 확인 응답과 재전송
    - Consumer는 언제나 장애가 발생할 수 윘기 때문에, 메세지를 잃어버리지 않기 위해 브로커는 “확인 응답”을 사용
    - Consumer는 메세지 처리가 끝났을 때 브로커가 큐에서 메세지를 삭제하도록 명시적으로 알림
    - 브로커가 확인 응답을 받지 않으면 Consumer가 정상적으로 처리했어도 재전송
    - 재전송 시 메세지 순서가 변경 될 수도 있음

### 파티셔닝된 로그

메세징 시스템: 브로커가 확인 응답을 Consumer로 부터 받으면 메세지를 삭제하고 복구가 불가능 → Consumer를 다시 실행해도 동일한 결과를 얻지 못함

데이터 베이스의 지속성 + 메세징 시스템의 알림 → 로그 기반 메세지 브로커

- 로그를 사용한 메세지 저장소 (Kafka)
    - Producer의 데이터는 로그(디스크에 저장된 추가 전용 레코드의 연속) 끝에 추가하고 Consumer는 순차적으로 읽어 메세지를 받음
    - Consumer가 로그 끝에 도달하면 새 메세지 추가 알림을 대기
    - 파티셔닝을 통해 독립적으로 읽고 쓰기가 가능한 로그 → 높은 처리량
    - 토픽: 같은 형식의 메세지를 전달하는 파티션 그룹
    - 각 파티션 내 브로커는 모든 메세지에 오프셋 (단조 증가 순번)을 부여 (다른 파티션 간 메세지 순서는 보장하지 않음)
    - 모든 메세지를 디스크에 저장하지만 여러 장비에 메세지를 파티셔닝해 처리량을 늘리고 메세지를 복제해 장애에 대비
- 로그 방식과 전통적인 메세징 방식의 비교 (?)
    - 로그 방식: 팬 아웃 방식 → Consumer가 서로 영향 없이 독립적으로 읽고 읽어도 로그에서 삭제되지 않음
    - 메세지를 개별 Consumer에게 할당하지 않고 Consumer 그룹 간 로드 밸런싱 하기 위해 브로커는 Consumer 그룹의 노드들에게 전체 파티션을 할당할 수 있음
    - 각 클라이언트는 할당된 파티션 메세지를 “모두” 소비
    - 단점
        - 노드 수는 많아야 해당 토픽의 로그 파티션 수로 제한 (같은 파티션 내 메세지는 같은 노드로 전달되기 때문)
        - 특정 메세지 처리가 느리면 파티션 내 후속 메세지 처리도 지연
    - 비교
        - 메세지 처리 비용이 비싸고 병렬화 처리하고 싶지만 메세지 순서는 중요하지 않음 → JMS/AMQP 방식 (Rabbit MQ)
        - 처리량이 많고 메세지 처리 속도가 빠르지만 메세지 순서가 중요 → 로그 방식 (Kafka)
- Consumer 오프셋
    - Consumer 현재 오프셋보다 작은 오프셋은 이미 처리, 큰 오프셋은 아직 처리 X → 브로커가 개별 메세지마다 확인 응답 추적 필요 없음
    - 데이터 베이스 복제에서 팔로워가 리더와 연결해 스냅숏 이후 발생한 데이터 변경을 로그 일련번호를 기준으로 요청하는 것 처럼 (메세지 브로커 = 리더, Consumer = 팔로워)
    - Consumer에 장애가 발생하면 Consumer 그룹 내 다른 노드에 파티션을 할당하고 마지막 오프셋부터 메세지를 처리 (장애 시점 처리되었지만 오프셋을 기록하지 못했다면 재처리 됨)
- 기타
    - 크기가 제한된 버퍼(디스크)로 구현해 버퍼가 가득차면 오래된 메세지 순서대로 버림 (Circular Buffer)
    - 모든 메세지를 디스크레 기록하기 때문에 메세지 양에 상관없이 처리량이 일정 (메세징 시스템과의 차이)
    - Consumer가 Producer 속도를 따라 잡지 못해 메세지가 버퍼에서 제거되면 메세지 유실 가능
    - Consumer가 죽으면 자원 소비가 중단되고 Consumer 오프셋만 남음 (메세지 브로커는 큐에 불필요한 메세지가 누적되어 활성화된 Consumer 메모리를 빼앗는 것을 막기 위해 Consumer가 사용하던 큐를 삭제해야?)
    - Consumer 오프셋은 재처리 등을 위해 쉽게 조작 가능 (일괄 처리와 유사)

## 데이터베이스와  스트림

이벤트: 특정 시점에 발생한 사건을 기록한 레코드

데이터 베이스에 기록하는 것도 이벤트임 (복제 로그: 리더는 데이터 베이스 기록 이벤트를 생산하고 팔로워는 스트림으로 동일한 복사본을 생성)

### 시스템 동기화 유지하기

복제본이 존재하는 환경에서 동기화는 필수 (주기적으로 덤프, dual write 등)

dual write의 문제: 동시에 쓰기가 발생하고 요청 순서가 교차되는 경우 영원히 데이터가 서로 일치하지 않음, 한 쪽만 성공할 수도 있음

→ 각각 dual write 하지 않고 리더-팔로워 관계로 단일 리더 복제 데이터 베이스를 유지한다면?

### 변경 데이터 캡쳐

- Change Data Capture: 데이터 베이스에 기록하는 데이터 변화를 관찰해 스트림 형태로 변경 내용을 제공해서 다른 시스템으로 복제할 수 있도록
- 로그 기반 메세지 브로커를 활용해 메세지 순서를 유지
- 비동기 방식으로 동작해 리더는 Consumer 상태 상관 없이 커밋
- 구현 방법
    - 트리거: 테이블 변화를 관찰하는 트리거. 오버헤드가 큼
    - 복제 로그 파싱: 스키마 변경 대응 필요. 그러나 견고함
- 초기 스냅숏: 모든 변겨 사항을 영구적으로 보관하기에는 공간 소비가 크기 때문에 변경 로그의 오프셋과 대응되는 스냅숏을 활용
- 로그 컴팩션: 주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거, 최근 갱신 내용만 유지 (갱신 수 > 데이터 수)

### 이벤트 소싱

- Event Sourcing: 애플리케이션 상태 변화를 불변한 변경 이벤트 로그로 저장 (데이터 베이스 단이 아닌 애플리케이션 수준에서)
- 사용자의 행동을 불변 이벤트로 기록 → 상황 발생 후 기록을 확인해 디버깅이 쉬움
- 이벤트 로그에서 현재 상태 파생하기
    - 수정 히스토리가 아닌 현재 상태를 제공하기 위해, 이벤트 로그를 적당한 애플리케이션 상태로 변환 필요 (결정적 - 재수행 하더라도 항상 동일한 상태)
    - 레코드 갱신용 Change Data Capture과 다르게 각 레코드 값이 기본키의 최신 이벤트로만 결정되지 않음 → 로그 컴팩션이 불가능
- 명령 vs 이벤트
    - 명령: 사용자 요청이 처음 도착
    - 이벤트: 명령이 실행가능한지 확인 후 무결성이 검증되고 명령이 승인되면 지속성있는 불변 이벤트로

### 상태와 스트림, 불변성

일반적으로 데이터 베이스는 현재 상태를 저장. 그러나 상태의 본질은 변하는 것

데이터베이스 갱신, 삭제로 상태가 변할 때 마다 해당 상태는 시간의 흐름에 따라 변한 이벤트의 마지막 결과

변경 로그를 지속성있게 저장하면, 현재 상태를 재생성 할 수 있음 (적분)

데이터 베이스는 변경 사항을 기록하는 트랜잭션 로그 부분 집합(로그 컴팩션)의 캐시

- 불변 이벤트의 장점
    - 거래가 발생하면 거래 정보를 원장(돈 교환 정보를 설명한 이벤트 로그)에 추가하는 방식으로 기록. 손익 등 회계는 원장의 거래 내역을 합산해서 만들 수 있음
    - 실수가 발생해도 원장을 고치거나 지우지 않고 실수를 보완하는 거래 내역을 추가 → 버그가 있는 시스템을 배포해 데이터 베이스가 틀어져도 덮어쓰지 않기 때문에 문제 상황 진단과 복구가 쉬움
- 동일한 이벤트 로그로 여러 가지 뷰 만들기
    - 데이터를 쓰는 형식과 읽는 형식을 분리해 다양한 읽기 뷰를 허용하면 유연성 good → CQRS(명령 질의 책임 분리)
    - 데이터 쓰기에 최적화된 이벤트 로그에서 읽기 최적화된 애플리케이션 상태로 전환 가능하다면 정규, 비정규화에 대한 논쟁은 의미가 없음 (변환 프로세스를 통해 이벤트 로그-뷰 사이 일관성을 유지)
- 동시성 제어
    - 이벤트 로그 소비가 비동기로 이루어진다면, 최종 데이터가 읽기 뷰에 반영되지 않은 상태에서 읽을 수 있는 가능성 존재
    - 이벤트 로그 추가와 읽기 뷰 갱신을 동기식으로 수행한다면 원자적 단위 결합 필요
    - 이벤트 로그와 읽기 뷰를 같은 저장 시스템에 저장하기
    - 또는, 분산 트랙잭션
    - 이벤트 로그로 현재 상태를 만들면 동시성 제어 측면에서 단순
        - 이벤트 소싱을 사용해 사용자 동작은 한 장소에 한 번 쓰기만 필요 → 원자적 단위
- 불변성의 한계
    - 갱신, 삭제가 빈번하다면 영구적으로 불변 히스토리를 유지하는 것은 사이즈가 커지고 파편화 문제 발생
    - 데이터를 진짜로 삭제(ex. 사생활 침해 규제로 개인 정보 지우기)하는 작업이 어려움

## 스트림 처리

스트림을 처리하는 방법

1. 이벤트에서 데이터를 꺼내 저장소 시스템에 기록하고 다른 클라이언트가 시스템에 데이터를 질의
2. 이벤트를 사용자에 직접 전송
3. 하나 이상의 입력 스트림을 처리(job) 해 하나 이상의 출력 파생 스트림을 생산 (이번 chapter에서 설명

스트림은 끝나지 않으므로 정렬, 전체 재시도 등은 비현실적

### 스트림 처리의 사용

스트림 처리는 특정 상황 발생 시 경고 해주는 모니터링 목적으로 적합

- 복잡한 이벤트 처리 (complex event processing)
    - 특정 이벤트 패턴을 검색해야 하는 애플리케이션에 적합
    - 데이터 베이스는 데이터를 영구적으로 저장하고 질의를 일시적으로 다루는 반면, CEP는 질의가 오랜 기간 저장되고 입력 스트림으로 들어오는 이벤트는 패턴에 매칭되는 질의를 찾음
- 스트림 분석
    - 연속한 특정 이벤트 패턴을 찾는 것 보다, 대량의 이벤트를 집계하고 통계적 지표를 뽑기 (이벤트 빈도, 이동 평균, 시간 가격 등)
    - 일반적으로 고정된 시간 간격(윈도우)을 기준으로
    - Kafka Streams, Google Cloud Dataflow
- 구체화 뷰 유지하기
    - 데이터 베이스 변경 스트림을 통해 캐시, 검색 색인 등 파생 데이터 시스템이 원본 데이터 베이스 최신 내용을 따라잡도록
    - 또 다른 뷰를 만들어 효율적으로 질의할 수 있게하고 기반 데이터가 변경될 때 뷰를 변경
    - 이벤트 소싱에서 애플리케이션의 상태 또한 구체화 뷰 (특정 시점이 아닌 모든 이벤트 필요, 스트림 분석과의 차이점)
    - Kafka Stream
- 스트림 상에서 검색하기
    - 먼저 문서를 색인하고 질의를 실행하는 것이 아닌 질의를 먼저 저장하고 문서는 질의를 지나가면서 실행됨
    - Elastic Search
- 메세지 전달과 RPC(?)

### 시간에 관한 추론

일괄 처리는 이벤트의 타임스탬프를 기준으로 이벤트 처리를 결정적으로 만들 수 있음

반면, 스트림 처리는 윈도우 시간을 결정할 때 처리하는 장비의 시스템 시계를 이용하고, 이벤트 처리가 지연되어 이벤트 생성과 처리 사이 간격이 크다면 문제 발생

- 이벤트 시간 vs 처리 시간
    - 메시지가 지연되면 메세지 순서를 예측하지 못하고 (466p 웹서버 예시)
    - 이벤트 요청 시간이 아닌 특정 처리 시간에 요청이 몰릴 수도 있음
- 준비 여부 인식
    - 특정 윈도우에 모든 이벤트가 도착했다고 확신할 수 없음 (언제 특정 윈도우는 종료를 선언해야 하는가?)
    - 낙오자 이벤트를 처리할 방법
        - 무시 (적은 비율이기 때문에)
        - 수정 값 발행 (이전 출력 취소해야 할 수도)
- 어떤 시계를 사용할 것인가?
    - 이벤트가 시스템 여러 지점에 버퍼링될 때 타임 스탬프를 어떻게 할당할 것인가? (사용률 지표를 오프라인 상태에서 로컬에 버퍼링 하다 온라인 상태가 되면 한 번에 전송)
    - 사용자 로컬 시계를 따라야 하지만 신뢰하기 어려움
    - 잘못된 장치 시계를 조정하는 방법 → 세 가지 타임스탬프를 로그로 남기기
        - 이벤트가 발생한 시간 (장치 시계)
        - 이벤트를 서버로 보낸 시간 (장치 시계)
        - 서버가 이벤트를 받은 시간 (서버 시계)
        - 2, 3번 오프셋을 1번 타임스탬프에 적용해 실제 발생 시간을 추정할 수 있음
- 윈도우 유형
    - 텀블링 윈도우
        - 고정 길이, 모든 이벤트는 정확히 한 윈도우에 속함
    - 홉핑 윈도우
        - 고정 길이, 결과를 매끄럽게 만들기 위해 윈도우 중첩
    - 슬라이딩 윈도우
        - 각 시간 간격 사이 발생한 모든 이벤트를 포함. 고정된 경계를 사용하지 않고 시간 기준 정렬한 이벤트를 버퍼에 유지하고 오래된 이벤트가 만료되면 윈도우에서 제거하는 방식으로 구현
    - 세션 윈도우
        - 고정된 기간이 없음. 같은 사용자가 짧은 시간동안 발생한 모든 이벤트를 그룹화해서 세션 윈도우를 정의

### 스트림 조인

- 스트림 스트림 조인
    - 조인을 위해 적절한 윈도우 선택이 필요 (예시: 한 시간 이내에 발생한 검색과 클릭을 조인)
    - 스트림 처리자가 상태를 유지해야 (모든 이벤트를 세션 ID로 색인하고 이벤트가 발생할 때 마다 같은 세션 ID로 도착한 다른 이벤트가 있는지 확인)
- 스트림 테이블 조인
    - 이벤트 스트림의 정보를 기반으로 데이터 베이스에서 추가 정보를 얻어 강화(enriching)
    - 네트워크 왕복 없이 로컬에서 데이터 베이스 질의가 가능하도록  스트림 처리자 내부에 데이터 베이스 사본을 적재한면 효율적
        - 데이터 베이스 사본은 최신 상태 유지가 중요 → 데이터 베이스 변경 로그를 스트림 처리자가 구독하는 방식 (CDC)
- 테이블 테이블 조인
    - 트위터 예시: 팔로우 한 사람 모두의 트윗을 순회하기 보다, 트윗이 전송될 때 사용자 별 “받은 편지함" 타임라인 캐시 사용
    - 새로운 트윗 이벤트가 발생했을 때 어떤 타임라인을 갱신해야하는지 알기 위해 각 사용자 별 팔로우 집합 데이터 베이스를 유지해야
    - 트윗과 팔로우 테이블을 조인하는 질의에 대한 구체화 뷰를 유지 (?)
- 조인의 시간 의존성
    - 이벤트 순서는 매우 중요. 다른 스트림이나 파티션 사이 순서 보장은 불가능
    - 시간에 따라 변하는 상태를 조인한다면, 어느 스트림 이벤트부터 변한 상태를 적용해야 하는가? → 시간 의존성 문제
    - 천천히 변하는 차원: 조인되는 레코드의 특정 버전을 가리키는 데 식별자를 사용 (세율이 바뀔 때 마다 식별자를 부여하고 송장에는 판매 시점의 세율 식별자 포함)

### 내결함성

스트림 처리자가 어떻게 결함에 견딜 수 있는가?

문제: 스트림은 무한하고 처리를 절대 완료할 수 없음

- 마이크로 일괄 처리: 스트림을 작은 블록으로 나누고 각 블록을 소형 일괄 처리
    - 블록 크기가 작을수록 스케줄링 비용이 큼
    - 블록 크기가 클수록 스트림 결과를 보기까지 지연 시간 발생
- 체크 포인트: 주기적으로 상태의 체크 포인트를 생성해 저장하고 스트림 연산에서 장애가 발생하면 최근 체크포인트에서 재시작
- 원자적 커밋 재검토: 완전히 처리가 성공했을 때만 이벤트 처리 부수 효과 발생
- 멱등성: 여러 번 연산을 수행해도 한 번 수행한 것도 같은 효과
